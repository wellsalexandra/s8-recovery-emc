{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNmMKIhLhwOQ3Xyu0VHwVrz"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjBDy_F-6p7Z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "from scipy.stats import multivariate_normal\n",
        "from halotools.empirical_models import PrebuiltHodModelFactory\n",
        "from halotools.mock_observables import wp\n",
        "from halotools.sim_manager import CachedHaloCatalog\n",
        "from halotools.sim_manager import sim_defaults\n",
        "from tabcorr import TabCorr\n",
        "from tabcorr import database\n",
        "from nautilus import Prior, Sampler\n",
        "import h5py\n",
        "import corner\n",
        "import os\n",
        "\n",
        "os.environ['TABCORR_DATABASE'] = './tabcorr'\n",
        "\n",
        "# Command Line Argument from submit_job.sh file\n",
        "parser = argparse.ArgumentParser(description=\"Fit observational data for a specified Box index\")\n",
        "parser.add_argument('box_index', type=int, help='The Box index to fit')\n",
        "parser.add_argument('max_rp_ave', type=float, help='Upper threshold value of rp_ave')\n",
        "args = parser.parse_args()\n",
        "box_index = args.box_index\n",
        "rp_ave_lim = args.max_rp_ave\n",
        "\n",
        "# Read in Observational Data for rp values\n",
        "df = pd.read_csv('./data_2301.08692/obs_1n.csv')\n",
        "\n",
        "# Read in mock measurements - covariance matrices\n",
        "mock_cov_all = pd.read_csv('./mocks/alex_mock_a_b/cov_a_b_with_aDS.csv', header=None)\n",
        "cov_mock_wp = mock_cov_all.iloc[:14, :14]\n",
        "cov_wp_arr = cov_mock_wp.to_numpy()\n",
        "cov_mock_ds = (mock_cov_all.iloc[14:28, 14:28] / 1e24)\n",
        "cov_ds_arr = cov_mock_ds.to_numpy()\n",
        "cov_mock_xi = mock_cov_all.iloc[28:70, 28:70]\n",
        "cov_xi_arr = cov_mock_xi.to_numpy()\n",
        "\n",
        "# Read in mock measurements\n",
        "mock_measurements = pd.read_csv('./mocks/alex_mock_a_b/mock_a_b_with_aDS.csv', sep=',')\n",
        "wp_mock = mock_measurements['wp'].values\n",
        "ds_mock = mock_measurements['ds'].values\n",
        "ds_mock = ds_mock / 1e12\n",
        "all_xi_mock = []\n",
        "all_xi_mock = all_xi_mock + list(mock_measurements['xi0'])\n",
        "all_xi_mock = all_xi_mock + list(mock_measurements['xi2'])\n",
        "all_xi_mock = all_xi_mock + list(mock_measurements['xi4'])\n",
        "all_xi_mock = pd.Series(all_xi_mock).values\n",
        "\n",
        "\n",
        "max_likelihoods = []\n",
        "evidences = []\n",
        "chi_squareds = []\n",
        "\n",
        "# For wp+ds\n",
        "halotab_wp = database.read('AemulusAlpha', 0.4, 'wp', i_cosmo=box_index, tab_config='default')\n",
        "halotab_ds = database.read('AemulusAlpha', 0.4, 'ds', i_cosmo=box_index, tab_config='default')\n",
        "\n",
        "# For RSD:\n",
        "halotab_xi0 = database.read('AemulusAlpha', 0.4, 'xi0', i_cosmo=box_index, tab_config='default')\n",
        "\n",
        "halotab_xi2 = database.read('AemulusAlpha', 0.4, 'xi2', i_cosmo=box_index, tab_config='default')\n",
        "\n",
        "halotab_xi4 = database.read('AemulusAlpha', 0.4, 'xi4', i_cosmo=box_index, tab_config='default')\n",
        "\n",
        "### Updated Model for Additional Parameters:\n",
        "\n",
        "from halotools.empirical_models import HodModelFactory\n",
        "from halotools.empirical_models import AssembiasZheng07Cens\n",
        "from halotools.empirical_models import AssembiasZheng07Sats\n",
        "\n",
        "\n",
        "class IncompleteAssembiasZheng07Cens(AssembiasZheng07Cens):\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        AssembiasZheng07Cens.__init__(self, **kwargs)\n",
        "        self.param_dict['f_compl'] = 1.0\n",
        "\n",
        "    def mean_occupation(self, **kwargs):\n",
        "        return (AssembiasZheng07Cens.mean_occupation(self, **kwargs) *\n",
        "                self.param_dict['f_compl'])\n",
        "\n",
        "\n",
        "cens_occ_model = IncompleteAssembiasZheng07Cens(\n",
        "prim_haloprop_key='halo_m200m', sec_haloprop_key='halo_vmax')\n",
        "sats_occ_model = AssembiasZheng07Sats(\n",
        "    prim_haloprop_key='halo_m200m', sec_haloprop_key='halo_vmax')\n",
        "\n",
        "model = HodModelFactory(centrals_occupation=cens_occ_model,\n",
        "                        satellites_occupation=sats_occ_model, redshift=0.4)\n",
        "\n",
        "\n",
        "rp_min = df['rp_min']\n",
        "rp_max = df['rp_max']\n",
        "rp_ave = 0.5 * (rp_min + rp_max)\n",
        "\n",
        "# MASK TO GET SUBSET OF RP VALUES\n",
        "tripled_rp_ave = pd.Series(list(rp_ave) + list(rp_ave) + list(rp_ave))\n",
        "tripled_rp_mask = tripled_rp_ave > rp_ave_lim\n",
        "\n",
        "rp_mask = rp_ave > rp_ave_lim\n",
        "rp_ave = rp_ave[rp_mask]\n",
        "\n",
        "wp_mock = wp_mock[rp_mask]\n",
        "ds_mock = ds_mock[rp_mask]\n",
        "all_xi_mock = all_xi_mock[tripled_rp_mask]\n",
        "\n",
        "## Apply mask to covariance matrices\n",
        "cov_wp_arr = cov_wp_arr[np.outer(rp_mask, rp_mask)].reshape(np.sum(rp_mask), np.sum(rp_mask))\n",
        "cov_ds_arr = cov_ds_arr[np.outer(rp_mask, rp_mask)].reshape(np.sum(rp_mask), np.sum(rp_mask))\n",
        "cov_xi_arr = cov_xi_arr[np.outer(tripled_rp_mask, tripled_rp_mask)].reshape(np.sum(tripled_rp_mask), np.sum(tripled_rp_mask))\n",
        "\n",
        "\n",
        "prior = Prior()  # initialize prior\n",
        "\n",
        "# HOD parameters\n",
        "prior.add_parameter('logM1', dist=(13.5, 15))\n",
        "prior.add_parameter('logM0', dist=(12, 15))\n",
        "prior.add_parameter('alpha', dist=(0.5, 2))\n",
        "prior.add_parameter('logMmin', dist=(12.5, 14))\n",
        "prior.add_parameter('sigma_logM', dist=(0.1, 1))\n",
        "\n",
        "# Phase Space parameters\n",
        "prior.add_parameter('alpha_s', dist=(0.8, 1.2))\n",
        "prior.add_parameter('log_eta', dist=(-0.477, 0.477))\n",
        "\n",
        "### ADDED PARAMETER FOR RSDs ONLY\n",
        "prior.add_parameter('alpha_c', dist=(0.0, 0.4))\n",
        "\n",
        "# Additional parameters\n",
        "prior.add_parameter('f_compl', dist=(0.5, 1.0))\n",
        "prior.add_parameter('mean_occupation_centrals_assembias_param1', dist=(-1, +1))\n",
        "prior.add_parameter('mean_occupation_satellites_assembias_param1', dist=(-1, +1))\n",
        "\n",
        "# Number density of galaxies\n",
        "ngal_info = pd.read_csv('ngal.csv')\n",
        "ngal = ngal_info['ngal']\n",
        "ngal_err = ngal_info['ngal_err'] # This is a singular value for the error\n",
        "cov_ngal = ngal_err**2\n",
        "\n",
        "def likelihood_combined(param_dict):\n",
        "    model.param_dict.update(param_dict)\n",
        "    ngal_wp, wp_mod = halotab_wp.predict(model)\n",
        "    wp_mod = wp_mod[rp_mask] # Exclude smallest scales\n",
        "    log_l_wp = multivariate_normal.logpdf(wp_mod, mean=wp_mock, cov=cov_wp_arr)\n",
        "\n",
        "    ngal_ds, ds_mod = halotab_ds.predict(model)\n",
        "    ds_mod = ds_mod / (1e12)\n",
        "    ds_mod = ds_mod[rp_mask] # Exclude smallest scales\n",
        "    log_l_ds = multivariate_normal.logpdf(ds_mod, mean=ds_mock, cov=cov_ds_arr)\n",
        "\n",
        "    # Compute likelihoods of ngal for wp and for ds\n",
        "    log_l_ngal_wp = multivariate_normal.logpdf(ngal_wp, mean=ngal, cov=cov_ngal)\n",
        "    log_l_ngal_ds = multivariate_normal.logpdf(ngal_ds, mean=ngal, cov=cov_ngal)\n",
        "\n",
        "    return log_l_wp + log_l_ds + log_l_ngal_wp + log_l_ngal_ds\n",
        "\n",
        "\n",
        "#    model.param_dict.update(param_dict)\n",
        "#    ngal_0, xi0_mod = halotab_xi0.predict(model)\n",
        "#    ngal_2, xi2_mod = halotab_xi2.predict(model)\n",
        "#    ngal_4, xi4_mod = halotab_xi4.predict(model)\n",
        "#\n",
        "#    all_xi_mod = []\n",
        "#    all_xi_mod = all_xi_mod + list(xi0_mod)\n",
        "#    all_xi_mod = all_xi_mod + list(xi2_mod)\n",
        "#    all_xi_mod = all_xi_mod + list(xi4_mod)\n",
        "#\n",
        "#    all_xi_mod = pd.Series(all_xi_mod).values\n",
        "#    all_xi_mod = all_xi_mod[tripled_rp_mask]\n",
        "#    all_xi_mod = np.asarray(all_xi_mod)\n",
        "#\n",
        "#    log_l_ngal_0 = multivariate_normal.logpdf(ngal_0, mean=ngal, cov=cov_ngal)\n",
        "#    log_l_ngal_2 = multivariate_normal.logpdf(ngal_2, mean=ngal, cov=cov_ngal)\n",
        "#    log_l_ngal_4 = multivariate_normal.logpdf(ngal_4, mean=ngal, cov=cov_ngal)\n",
        "#\n",
        "#    log_l_xi = multivariate_normal.logpdf(all_xi_mod, mean=all_xi_mock, cov=cov_xi_arr, allow_singular=True)\n",
        "#    return log_l_xi + log_l_ngal_0 + log_l_ngal_2 + log_l_ngal_4\n",
        "\n",
        "sampler = Sampler(prior, likelihood_combined, filepath='box_'+str(box_index)+'.hdf5', n_live=1000, resume=False)\n",
        "sampler.run(verbose=False)\n",
        "\n",
        "points, log_w, log_l = sampler.posterior()\n",
        "log_l_max = np.max(log_l)\n",
        "\n",
        "# Calculate chi-squareds:\n",
        "\n",
        "# For wp+ds:\n",
        "neg_chi_squared = 2 * log_l_max + (len(cov_wp_arr) * np.log(2 * np.pi) + np.linalg.slogdet(cov_wp_arr)[1]) + (len(cov_ds_arr) * np.log(2 * np.pi) + np.linalg.slogdet(cov_ds_arr)[1]) + (len(cov_ngal) * np.log(2 * np.pi) + np.linalg.slogdet(cov_ngal)[1])\n",
        "chi_squared = -1 * neg_chi_squared\n",
        "# For RSDs:\n",
        "#neg_chi_squared = 2 * log_l_max + (len(cov_xi_arr) * np.log(2 * np.pi) + np.linalg.slogdet(cov_xi_arr)[1])\n",
        "#chi_squared = -1 * neg_chi_squared\n",
        "\n",
        "max_likelihoods.append(log_l_max)\n",
        "evidences.append(sampler.log_z)\n",
        "chi_squareds.append(chi_squared)\n",
        "\n",
        "file = open('output'+str(box_index)+'.txt', 'w')\n",
        "file.write(f\"Max Likelihood: {max_likelihoods[0]}\\n\")\n",
        "file.write(f\"Evidence: {evidences[0]}\\n\")\n",
        "file.write(f\"Chi-Squared: {chi_squareds[0]}\\n\")\n",
        "file.close()\n"
      ]
    }
  ]
}